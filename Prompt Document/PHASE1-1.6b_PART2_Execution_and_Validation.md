# PHASE1-1.6b PART2: Reserved Instance Workflow - Execution and Validation

**Phase:** Cost Agent - Week 2  
**Workflow:** Reserved Instance (RI) Optimization  
**Type:** Execution Guide  
**Date:** October 22, 2025

---

## ðŸ“‹ TABLE OF CONTENTS

1. [Quick Start](#quick-start)
2. [Pre-Execution Checklist](#pre-execution-checklist)
3. [Step-by-Step Execution](#step-by-step-execution)
4. [Validation Tests](#validation-tests)
5. [Success Criteria](#success-criteria)
6. [Troubleshooting](#troubleshooting)
7. [Post-Completion Tasks](#post-completion-tasks)
8. [Metrics and Monitoring](#metrics-and-monitoring)

---

## ðŸš€ QUICK START

### Implementation Order
```
1. Create RI analysis module (ri_analyze.py)
2. Create RI recommendation engine (ri_recommend.py)
3. Create ROI calculator (ri_roi.py)
4. Create RI workflow (ri_optimization.py)
5. Create validation models (ri_optimization.py models)
6. Enhance metrics storage (clickhouse_metrics.py)
7. Enhance Prometheus metrics (prometheus_metrics.py)
8. Create comprehensive tests (test_ri_production.py)
9. Run tests and validate
10. Create summary documentation
```

### Expected Timeline
- **Code Implementation:** 2-3 hours
- **Testing:** 30-45 minutes
- **Documentation:** 15-30 minutes
- **Total:** 3-4 hours

---

## âœ… PRE-EXECUTION CHECKLIST

### Dependencies Verified
- [x] PHASE1-1.6 (Spot Migration) completed
- [x] Python 3.13+ installed
- [x] Virtual environment activated
- [x] All dependencies installed:
  ```bash
  pip install clickhouse-driver prometheus-client tenacity
  ```

### Files Exist
- [x] `src/collectors/aws/ec2.py` - EC2 collector
- [x] `src/collectors/aws/rds.py` - RDS collector (if needed)
- [x] `src/database/clickhouse_metrics.py` - Metrics storage
- [x] `src/monitoring/prometheus_metrics.py` - Prometheus metrics
- [x] `src/workflows/spot_migration.py` - Reference workflow

### Configuration Ready
- [x] ClickHouse connection settings (optional)
- [x] Prometheus endpoint configured (optional)
- [x] Cloud credentials available (for testing)

---

## ðŸ”¨ STEP-BY-STEP EXECUTION

### STEP 1: Create RI Analysis Module âœ…

**File:** `src/nodes/ri_analyze.py`

**Implementation:**
```python
"""
Reserved Instance analysis node.
Analyzes historical usage patterns to identify RI candidates.
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from statistics import mean, stdev

from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)

logger = logging.getLogger(__name__)


# Custom Exceptions
class RIAnalysisError(Exception):
    """Base exception for RI analysis errors"""
    pass


class InsufficientUsageDataError(RIAnalysisError):
    """Raised when insufficient usage data is available"""
    pass


class UsageDataCollectionError(RIAnalysisError):
    """Raised when usage data collection fails"""
    pass


@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception_type(UsageDataCollectionError)
)
def analyze_usage_patterns(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Analyze instance usage patterns to identify RI candidates.
    
    Args:
        state: Workflow state containing instance_usage data
        
    Returns:
        Updated state with stable_workloads and usage_patterns
    """
    try:
        logger.info(
            f"Analyzing usage patterns for customer {state['customer_id']}",
            extra={
                "request_id": state["request_id"],
                "customer_id": state["customer_id"],
                "analysis_period_days": state.get("analysis_period_days", 30)
            }
        )
        
        instance_usage = state.get("instance_usage", [])
        
        if not instance_usage:
            raise InsufficientUsageDataError("No usage data available for analysis")
        
        min_uptime = state.get("min_uptime_percent", 80.0)
        min_cost = state.get("min_monthly_cost", 50.0)
        
        # Identify stable workloads
        stable_workloads = []
        usage_patterns = {}
        
        for instance in instance_usage:
            instance_id = instance.get("instance_id")
            
            # Calculate metrics
            metrics = calculate_utilization_metrics(instance)
            
            # Check if instance qualifies for RI
            if (metrics["uptime_percent"] >= min_uptime and 
                metrics["monthly_cost"] >= min_cost):
                
                # Detect usage pattern
                pattern = detect_usage_pattern(instance.get("usage_history", []))
                
                stable_workload = {
                    "instance_id": instance_id,
                    "instance_type": instance.get("instance_type"),
                    "region": instance.get("region"),
                    "service_type": instance.get("service_type", "ec2"),
                    "uptime_percent": metrics["uptime_percent"],
                    "monthly_cost": metrics["monthly_cost"],
                    "usage_pattern": pattern,
                    "confidence_score": calculate_confidence_score(metrics, pattern),
                    "metrics": metrics
                }
                
                stable_workloads.append(stable_workload)
                usage_patterns[instance_id] = pattern
        
        logger.info(
            f"Found {len(stable_workloads)} stable workloads for RI consideration",
            extra={
                "request_id": state["request_id"],
                "customer_id": state["customer_id"],
                "stable_workloads_count": len(stable_workloads)
            }
        )
        
        state["stable_workloads"] = stable_workloads
        state["usage_patterns"] = usage_patterns
        state["workflow_status"] = "analyzed"
        state["current_phase"] = "analysis_complete"
        
        return state
        
    except InsufficientUsageDataError as e:
        logger.error(f"Insufficient usage data: {e}")
        state["workflow_status"] = "failed"
        state["error_message"] = str(e)
        state["success"] = False
        return state
        
    except Exception as e:
        logger.error(f"Unexpected error in usage analysis: {e}", exc_info=True)
        state["workflow_status"] = "failed"
        state["error_message"] = f"Analysis failed: {str(e)}"
        state["success"] = False
        return state


def calculate_utilization_metrics(instance: Dict[str, Any]) -> Dict[str, Any]:
    """
    Calculate utilization metrics for an instance.
    
    Args:
        instance: Instance data with usage history
        
    Returns:
        Dictionary of calculated metrics
    """
    usage_history = instance.get("usage_history", [])
    
    if not usage_history:
        return {
            "uptime_percent": 0.0,
            "monthly_cost": 0.0,
            "avg_cpu": 0.0,
            "avg_memory": 0.0,
            "variance": 0.0
        }
    
    # Calculate uptime percentage
    total_hours = len(usage_history)
    running_hours = sum(1 for h in usage_history if h.get("state") == "running")
    uptime_percent = (running_hours / total_hours * 100) if total_hours > 0 else 0
    
    # Calculate average CPU and memory
    cpu_values = [h.get("cpu_utilization", 0) for h in usage_history if h.get("state") == "running"]
    memory_values = [h.get("memory_utilization", 0) for h in usage_history if h.get("state") == "running"]
    
    avg_cpu = mean(cpu_values) if cpu_values else 0
    avg_memory = mean(memory_values) if memory_values else 0
    
    # Calculate variance (for pattern detection)
    variance = stdev(cpu_values) if len(cpu_values) > 1 else 0
    
    # Calculate monthly cost
    hourly_cost = instance.get("hourly_cost", 0)
    monthly_cost = hourly_cost * 730  # Average hours per month
    
    return {
        "uptime_percent": round(uptime_percent, 2),
        "monthly_cost": round(monthly_cost, 2),
        "avg_cpu": round(avg_cpu, 2),
        "avg_memory": round(avg_memory, 2),
        "variance": round(variance, 2),
        "total_hours_analyzed": total_hours,
        "running_hours": running_hours
    }


def detect_usage_pattern(usage_history: List[Dict[str, Any]]) -> str:
    """
    Detect usage pattern type from historical data.
    
    Args:
        usage_history: List of hourly usage data points
        
    Returns:
        Pattern type: "steady", "growing", "seasonal", or "declining"
    """
    if not usage_history or len(usage_history) < 24:
        return "unknown"
    
    # Extract CPU utilization over time
    cpu_values = [h.get("cpu_utilization", 0) for h in usage_history]
    
    if len(cpu_values) < 24:
        return "unknown"
    
    # Calculate trend (simple linear regression slope)
    n = len(cpu_values)
    x = list(range(n))
    x_mean = mean(x)
    y_mean = mean(cpu_values)
    
    numerator = sum((x[i] - x_mean) * (cpu_values[i] - y_mean) for i in range(n))
    denominator = sum((x[i] - x_mean) ** 2 for i in range(n))
    
    slope = numerator / denominator if denominator != 0 else 0
    
    # Calculate variance
    variance = stdev(cpu_values) if len(cpu_values) > 1 else 0
    
    # Classify pattern
    if abs(slope) < 0.01 and variance < 10:
        return "steady"
    elif slope > 0.05:
        return "growing"
    elif slope < -0.05:
        return "declining"
    elif variance > 20:
        return "seasonal"
    else:
        return "steady"


def calculate_confidence_score(
    metrics: Dict[str, Any],
    pattern: str
) -> float:
    """
    Calculate confidence score for RI recommendation.
    
    Args:
        metrics: Utilization metrics
        pattern: Usage pattern type
        
    Returns:
        Confidence score between 0.0 and 1.0
    """
    score = 0.0
    
    # Uptime contribution (40%)
    uptime = metrics.get("uptime_percent", 0)
    if uptime >= 95:
        score += 0.40
    elif uptime >= 90:
        score += 0.35
    elif uptime >= 85:
        score += 0.30
    elif uptime >= 80:
        score += 0.25
    
    # Pattern contribution (30%)
    pattern_scores = {
        "steady": 0.30,
        "growing": 0.25,
        "seasonal": 0.15,
        "declining": 0.05,
        "unknown": 0.10
    }
    score += pattern_scores.get(pattern, 0.10)
    
    # Variance contribution (20%)
    variance = metrics.get("variance", 100)
    if variance < 5:
        score += 0.20
    elif variance < 10:
        score += 0.15
    elif variance < 20:
        score += 0.10
    else:
        score += 0.05
    
    # Cost contribution (10%)
    monthly_cost = metrics.get("monthly_cost", 0)
    if monthly_cost >= 500:
        score += 0.10
    elif monthly_cost >= 200:
        score += 0.08
    elif monthly_cost >= 100:
        score += 0.06
    else:
        score += 0.04
    
    return round(min(score, 1.0), 2)
```

**Validation:**
```bash
# Test the module
python -c "from src.nodes.ri_analyze import analyze_usage_patterns; print('âœ… RI analysis module imported successfully')"
```

---

### STEP 2: Create RI Recommendation Engine âœ…

**File:** `src/nodes/ri_recommend.py`

**Key Implementation Points:**
1. RI matching logic for AWS/GCP/Azure
2. Savings calculation for different terms (1yr, 3yr)
3. Payment option comparison (All Upfront, Partial, No Upfront)
4. Risk assessment based on usage patterns
5. Recommendation ranking by ROI

**Expected Output:**
- List of RI recommendations with savings projections
- Optimal term and payment option for each
- Risk level and confidence score

---

### STEP 3: Create ROI Calculator âœ…

**File:** `src/nodes/ri_roi.py`

**Key Calculations:**
1. Break-even point (months to recover upfront cost)
2. NPV (Net Present Value) calculation
3. Total savings over term
4. Risk-adjusted ROI
5. Utilization risk assessment

**Formula Examples:**
```python
# Break-even
breakeven_months = upfront_cost / monthly_savings

# Total savings over 1 year
total_savings_1yr = (monthly_savings * 12) - upfront_cost

# Total savings over 3 years
total_savings_3yr = (monthly_savings * 36) - upfront_cost

# Savings percentage
savings_percent = (monthly_savings / on_demand_monthly_cost) * 100
```

---

### STEP 4: Create RI Workflow âœ…

**File:** `src/workflows/ri_optimization.py`

**LangGraph Structure:**
```python
workflow = StateGraph(RIWorkflowState)

# Add nodes
workflow.add_node("collect_usage", collect_usage_data_node)
workflow.add_node("analyze_usage", analyze_usage_patterns)
workflow.add_node("generate_recommendations", generate_ri_recommendations)
workflow.add_node("calculate_roi", calculate_roi_analysis)
workflow.add_node("coordinate_approval", coordinate_approval)

# Add edges
workflow.set_entry_point("collect_usage")
workflow.add_edge("collect_usage", "analyze_usage")
workflow.add_edge("analyze_usage", "generate_recommendations")
workflow.add_edge("generate_recommendations", "calculate_roi")
workflow.add_edge("calculate_roi", "coordinate_approval")
workflow.add_edge("coordinate_approval", END)
```

**Integration with Metrics:**
```python
# Record start
from src.monitoring.prometheus_metrics import record_ri_optimization_start
record_ri_optimization_start(customer_id, cloud_provider)

# Run workflow
result = await workflow.run(...)

# Record completion
from src.monitoring.prometheus_metrics import record_ri_optimization_complete
record_ri_optimization_complete(customer_id, cloud_provider, duration, savings, recs)

# Store in ClickHouse
from src.database.clickhouse_metrics import get_metrics_client
await get_metrics_client().insert_ri_optimization_event(event_data)
```

---

### STEP 5: Create Validation Models âœ…

**File:** `src/models/ri_optimization.py`

**Models to Create:**
1. `RIOptimizationRequest` - Input validation
2. `RIRecommendation` - Single recommendation
3. `RIOptimizationResponse` - Complete response
4. `RIWorkflowState` - TypedDict for LangGraph

**Validation Rules:**
- customer_id: `^[a-zA-Z0-9_-]{1,64}$`
- cloud_provider: `aws|gcp|azure`
- service_types: Valid service list
- analysis_period_days: 7-90 days
- min_uptime_percent: 50-100%

---

### STEP 6: Enhance ClickHouse Metrics âœ…

**File:** `src/database/clickhouse_metrics.py`

**Add to existing class:**
```python
def _ensure_tables(self):
    # ... existing spot_migration_events table ...
    
    # Add RI optimization events table
    self.client.execute("""
        CREATE TABLE IF NOT EXISTS ri_optimization_events (
            timestamp DateTime,
            request_id String,
            customer_id String,
            cloud_provider String,
            service_type String,
            workflow_phase String,
            instances_analyzed UInt32,
            stable_workloads_found UInt32,
            ris_recommended UInt32,
            total_upfront_cost Float64,
            monthly_savings Float64,
            annual_savings Float64,
            three_year_savings Float64,
            average_breakeven_months Float32,
            one_year_ris UInt32,
            three_year_ris UInt32,
            success UInt8,
            error_message String,
            duration_ms UInt32
        ) ENGINE = MergeTree()
        ORDER BY (timestamp, customer_id)
        TTL timestamp + INTERVAL 90 DAY
    """)

async def insert_ri_optimization_event(self, event: Dict[str, Any]) -> None:
    """Insert RI optimization event"""
    # Implementation
```

---

### STEP 7: Enhance Prometheus Metrics âœ…

**File:** `src/monitoring/prometheus_metrics.py`

**Add new metrics:**
```python
# Counters
ri_optimizations_total = Counter(...)
ri_recommendations_total = Counter(...)

# Histograms
ri_savings_amount_dollars = Histogram(...)
ri_breakeven_months = Histogram(...)
ri_optimization_duration_seconds = Histogram(...)

# Gauges
ri_coverage_percent = Gauge(...)
ri_utilization_percent = Gauge(...)

# Helper functions
def record_ri_optimization_start(customer_id, cloud_provider):
    ri_optimizations_total.labels(
        customer_id=customer_id,
        cloud_provider=cloud_provider,
        status="started"
    ).inc()

def record_ri_optimization_complete(...):
    # Implementation
```

---

### STEP 8: Create Comprehensive Tests âœ…

**File:** `tests/test_ri_production.py`

**Test Structure:**
```python
import pytest
from src.workflows.ri_optimization import ProductionRIOptimizationWorkflow
from src.nodes.ri_analyze import analyze_usage_patterns, calculate_confidence_score
from src.nodes.ri_recommend import generate_ri_recommendations
from src.nodes.ri_roi import calculate_roi_analysis
from src.models.ri_optimization import RIOptimizationRequest, RIRecommendation

class TestRIAnalysis:
    """Test RI usage analysis"""
    
    def test_identify_stable_workloads(self):
        """Test identification of RI candidates"""
        
    def test_detect_steady_pattern(self):
        """Test steady usage pattern detection"""
        
    def test_detect_growing_pattern(self):
        """Test growing usage pattern detection"""
        
    def test_confidence_score_calculation(self):
        """Test confidence score calculation"""

class TestRIRecommendation:
    """Test RI recommendation engine"""
    
    def test_generate_recommendations(self):
        """Test RI recommendation generation"""
        
    def test_calculate_savings(self):
        """Test savings calculation"""
        
    def test_payment_option_selection(self):
        """Test payment option recommendation"""

class TestROICalculation:
    """Test ROI calculations"""
    
    def test_breakeven_calculation(self):
        """Test break-even point calculation"""
        
    def test_total_savings_calculation(self):
        """Test total savings over term"""
        
    def test_risk_assessment(self):
        """Test utilization risk assessment"""

class TestRIWorkflow:
    """Test complete RI workflow"""
    
    @pytest.mark.asyncio
    async def test_complete_workflow(self):
        """Test end-to-end RI optimization"""

class TestRIMetrics:
    """Test RI metrics recording"""
    
    @pytest.mark.asyncio
    async def test_clickhouse_insert(self):
        """Test ClickHouse event insertion"""
        
    def test_prometheus_metrics(self):
        """Test Prometheus metrics recording"""

class TestRIValidation:
    """Test input validation"""
    
    def test_valid_request(self):
        """Test valid RI optimization request"""
        
    def test_invalid_analysis_period(self):
        """Test invalid analysis period"""
        
    def test_invalid_service_type(self):
        """Test invalid service type"""
```

**Target:** 25+ tests covering all scenarios

---

## âœ… VALIDATION TESTS

### Test Execution Commands

```bash
# Run all RI tests
pytest tests/test_ri_production.py -v

# Run specific test class
pytest tests/test_ri_production.py::TestRIAnalysis -v

# Run with coverage
pytest tests/test_ri_production.py --cov=src.nodes.ri_analyze --cov=src.nodes.ri_recommend --cov=src.workflows.ri_optimization -v

# Run integration tests only
pytest tests/test_ri_production.py::TestRIWorkflow -v
```

### Expected Results

```
tests/test_ri_production.py::TestRIAnalysis::test_identify_stable_workloads PASSED
tests/test_ri_production.py::TestRIAnalysis::test_detect_steady_pattern PASSED
tests/test_ri_production.py::TestRIAnalysis::test_confidence_score_calculation PASSED
tests/test_ri_production.py::TestRIRecommendation::test_generate_recommendations PASSED
tests/test_ri_production.py::TestRIRecommendation::test_calculate_savings PASSED
tests/test_ri_production.py::TestROICalculation::test_breakeven_calculation PASSED
tests/test_ri_production.py::TestRIWorkflow::test_complete_workflow PASSED
tests/test_ri_production.py::TestRIMetrics::test_clickhouse_insert PASSED
tests/test_ri_production.py::TestRIValidation::test_valid_request PASSED

========================= 25 passed in 12.5s =========================
```

---

## ðŸŽ¯ SUCCESS CRITERIA

### Code Quality
- âœ… All tests passing (25/25)
- âœ… Code coverage > 85%
- âœ… No syntax errors
- âœ… No import errors
- âœ… Proper type hints
- âœ… Comprehensive docstrings

### Functionality
- âœ… Usage pattern analysis working
- âœ… RI recommendations generated correctly
- âœ… ROI calculations accurate
- âœ… Break-even analysis correct
- âœ… Multi-cloud support (AWS/GCP/Azure)
- âœ… Error handling robust

### Integration
- âœ… ClickHouse metrics stored
- âœ… Prometheus metrics exposed
- âœ… Cloud collectors integrated
- âœ… LangGraph workflow functional

### Security
- âœ… Input validation working
- âœ… No SQL injection vulnerabilities
- âœ… Proper error messages
- âœ… No sensitive data in logs

---

## ðŸ”§ TROUBLESHOOTING

### Common Issues

**Issue 1: Import Errors**
```
ModuleNotFoundError: No module named 'src.nodes.ri_analyze'
```
**Solution:**
- Ensure file created in correct location
- Check `__init__.py` exists in `src/nodes/`
- Verify virtual environment activated

**Issue 2: ClickHouse Connection Failed**
```
Failed to create ClickHouse tables: Connection refused
```
**Solution:**
- ClickHouse is optional for testing
- Graceful degradation should handle this
- Check `test_graceful_degradation_no_clickhouse` passes

**Issue 3: Test Failures**
```
AssertionError: assert 12.5 == 13
```
**Solution:**
- Check break-even calculation formula
- Verify rounding logic
- Review test expectations

**Issue 4: Collector Not Found**
```
AttributeError: module 'src.collectors' has no attribute 'aws'
```
**Solution:**
- Use correct collector class names
- Check import paths
- Mock collectors in tests

---

## ðŸ“‹ POST-COMPLETION TASKS

### 1. Create Summary Documents âœ…

**Files to Create:**
- `PHASE1-1.6b-IMPLEMENTATION-SUMMARY.md`
- `PHASE1-1.6b-VALIDATION-SUMMARY.md`

**Content:**
- What was implemented
- Test results
- Key achievements
- Next steps

### 2. Update Main Documentation âœ…

Update `README.md` with:
- PHASE1-1.6b completion status
- New endpoints/features
- Usage examples

### 3. Code Review Checklist âœ…

- [ ] All files follow project structure
- [ ] Code style consistent
- [ ] No hardcoded values
- [ ] Error handling comprehensive
- [ ] Logging properly configured
- [ ] Tests comprehensive
- [ ] Documentation complete

### 4. Deployment Preparation âœ…

- [ ] Staging environment ready
- [ ] Configuration files updated
- [ ] Environment variables set
- [ ] Monitoring dashboards created
- [ ] Alerting rules configured

---

## ðŸ“Š METRICS AND MONITORING

### ClickHouse Queries

**Get RI optimization summary:**
```sql
SELECT 
    customer_id,
    COUNT(*) as optimization_count,
    SUM(ris_recommended) as total_ris_recommended,
    SUM(annual_savings) as total_annual_savings,
    AVG(average_breakeven_months) as avg_breakeven
FROM ri_optimization_events
WHERE timestamp >= now() - INTERVAL 30 DAY
GROUP BY customer_id
ORDER BY total_annual_savings DESC
```

**Get success rate:**
```sql
SELECT 
    cloud_provider,
    countIf(success = 1) * 100.0 / count(*) as success_rate
FROM ri_optimization_events
WHERE timestamp >= now() - INTERVAL 7 DAY
GROUP BY cloud_provider
```

### Prometheus Queries

**RI optimization rate:**
```promql
rate(ri_optimizations_total[5m])
```

**Average savings per customer:**
```promql
avg(ri_savings_amount_dollars) by (customer_id)
```

**Average break-even period:**
```promql
avg(ri_breakeven_months) by (payment_option)
```

### Grafana Dashboard Panels

1. **RI Optimizations Over Time** - Line chart
2. **Total Projected Savings** - Stat panel
3. **Average Break-even Period** - Gauge
4. **RI Recommendations by Term** - Pie chart
5. **Success Rate by Cloud Provider** - Bar chart
6. **Top Customers by Savings** - Table

---

## ðŸŽ‰ COMPLETION CHECKLIST

### Implementation
- [ ] `src/nodes/ri_analyze.py` created
- [ ] `src/nodes/ri_recommend.py` created
- [ ] `src/nodes/ri_roi.py` created
- [ ] `src/workflows/ri_optimization.py` created
- [ ] `src/models/ri_optimization.py` created
- [ ] `src/database/clickhouse_metrics.py` enhanced
- [ ] `src/monitoring/prometheus_metrics.py` enhanced

### Testing
- [ ] `tests/test_ri_production.py` created
- [ ] All tests passing (25/25)
- [ ] Code coverage > 85%
- [ ] Integration tests working

### Documentation
- [ ] PART1 (Code Implementation) complete
- [ ] PART2 (Execution & Validation) complete
- [ ] Implementation summary created
- [ ] Validation summary created
- [ ] Code comments comprehensive

### Deployment
- [ ] Code reviewed
- [ ] Staging deployment successful
- [ ] Metrics verified
- [ ] Ready for production

---

## ðŸš€ NEXT PHASE

After PHASE1-1.6b completion:

**PHASE1-1.6c: Right-Sizing Workflow**
- Instance size optimization
- Over-provisioned resource detection
- Right-sizing recommendations
- Performance impact analysis

---

**Document Version:** 1.0  
**Last Updated:** October 22, 2025  
**Status:** Ready for Execution
